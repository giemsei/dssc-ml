{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce8bf34-5077-4b39-ae81-afd6db3d3bbf",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7067e-7426-4923-b120-a5cc47e2b328",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c52f4a-8fab-45ad-86b8-45a7f1f0e87c",
   "metadata": {},
   "source": [
    "TODO\n",
    "- none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d96a7-1686-4c83-b806-cfe85b8f9d2a",
   "metadata": {},
   "source": [
    "Find the most recent dataset and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b44b7c-5c61-4219-ae2b-2784dba2e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath = \"data\"\\n\\n# get the most recent dataset (ordered by the date in the name)\\nfilelist = os.listdir(\"data\") # get the list of files\\nmatching = [s for s in filelist if \"dataset\" in s] # filter only by files containing \"dataset\" in the name\\nmatching.sort(reverse=True)\\n\\nprint(matching[0])\\n\\n# load the dataset\\ndf = pd.read_csv(path+\"/\"+matching[0])\\ndf = df.rename(columns={\"Text\": \"text\", \"Retweet\": \"retweet\", \"Likes\": \"likes\", 3: \"user_id\"})\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "'''\n",
    "path = \"data\"\n",
    "\n",
    "# get the most recent dataset (ordered by the date in the name)\n",
    "filelist = os.listdir(\"data\") # get the list of files\n",
    "matching = [s for s in filelist if \"dataset\" in s] # filter only by files containing \"dataset\" in the name\n",
    "matching.sort(reverse=True)\n",
    "\n",
    "print(matching[0])\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(path+\"/\"+matching[0])\n",
    "df = df.rename(columns={\"Text\": \"text\", \"Retweet\": \"retweet\", \"Likes\": \"likes\", 3: \"user_id\"})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1265be5c-fe2d-456d-acca-6b38024a89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>X</th>\n",
       "      <th>likes</th>\n",
       "      <th>followers</th>\n",
       "      <th>popularity</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i feel so shitty about my body today I want to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.829554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>i want you to make yourself your lunch and let...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1.710159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>..Wanna go get some lunch?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.417281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>hello! not new to edtwt (switched accs) + look...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.127792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>20-30 min wait to get a dosa at avrebele mela ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140</th>\n",
       "      <td>25390</td>\n",
       "      <td>does the 'thinking' time counter on CELTX vs t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1.405926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141</th>\n",
       "      <td>25391</td>\n",
       "      <td>Pinto Beans w/smoked Turkey Wings and cornbrea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>0.575502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20142</th>\n",
       "      <td>25393</td>\n",
       "      <td>Back to normal life in Los Angeles means back ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>2.237816</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>25396</td>\n",
       "      <td>At some point a certain brand of skinny fitnes...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.272493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>25398</td>\n",
       "      <td>Ordered a portable smoothie maker for when I'm...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.756539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20145 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                                  X  likes  \\\n",
       "0          0  i feel so shitty about my body today I want to...    1.0   \n",
       "1          4  i want you to make yourself your lunch and let...    3.0   \n",
       "2          6                         ..Wanna go get some lunch?    0.0   \n",
       "3          9  hello! not new to edtwt (switched accs) + look...    4.0   \n",
       "4         10  20-30 min wait to get a dosa at avrebele mela ...    0.0   \n",
       "...      ...                                                ...    ...   \n",
       "20140  25390  does the 'thinking' time counter on CELTX vs t...    2.0   \n",
       "20141  25391  Pinto Beans w/smoked Turkey Wings and cornbrea...    1.0   \n",
       "20142  25393  Back to normal life in Los Angeles means back ...   11.0   \n",
       "20143  25396  At some point a certain brand of skinny fitnes...    7.0   \n",
       "20144  25398  Ordered a portable smoothie maker for when I'm...    6.0   \n",
       "\n",
       "       followers  popularity  y  \n",
       "0          343.0    0.829554  1  \n",
       "1          277.0    1.710159  2  \n",
       "2          329.0    0.417281  0  \n",
       "3           14.0    3.127792  2  \n",
       "4           98.0    0.489201  0  \n",
       "...          ...         ... ..  \n",
       "20140      138.0    1.405926  1  \n",
       "20141     2088.0    0.575502  1  \n",
       "20142     6372.0    2.237816  2  \n",
       "20143      377.0    3.272493  2  \n",
       "20144      483.0    2.756539  2  \n",
       "\n",
       "[20145 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#path = \"datasets/619439/\"\n",
    "path = \"datasets/joined/\"\n",
    "#path = \"\"\n",
    "#df = pd.read_csv(path+\"debug_set_614548.csv\")\n",
    "#df = pd.read_csv(path+\"debug_set_619439.csv\")\n",
    "#df = pd.read_csv(path+\"dataset_pop.csv\")\n",
    "df = pd.read_csv(path+\"dataset_pop.csv\")\n",
    "#df = pd.read_csv(path+\"dataset_raw.csv\")\n",
    "\n",
    "\n",
    "#path = \"datasets/619439/\"\n",
    "#df = pd.concat([df, pd.read_csv(path+\"dataset_pop.csv\")])\n",
    "df = df.rename(columns={\"text\": \"X\", \"pop_level\": \"y\"})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bc3db-54b4-46fa-8829-cd02cdbf89a6",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "Drop duplicates observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a0280a-5b6c-4bc2-b40b-5217307c50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19741, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>X</th>\n",
       "      <th>likes</th>\n",
       "      <th>followers</th>\n",
       "      <th>popularity</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i feel so shitty about my body today I want to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.829554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>i want you to make yourself your lunch and let...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1.710159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>..Wanna go get some lunch?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.417281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>hello! not new to edtwt (switched accs) + look...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.127792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>20-30 min wait to get a dosa at avrebele mela ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140</th>\n",
       "      <td>25390</td>\n",
       "      <td>does the 'thinking' time counter on CELTX vs t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1.405926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141</th>\n",
       "      <td>25391</td>\n",
       "      <td>Pinto Beans w/smoked Turkey Wings and cornbrea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>0.575502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20142</th>\n",
       "      <td>25393</td>\n",
       "      <td>Back to normal life in Los Angeles means back ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>2.237816</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>25396</td>\n",
       "      <td>At some point a certain brand of skinny fitnes...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.272493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>25398</td>\n",
       "      <td>Ordered a portable smoothie maker for when I'm...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.756539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19741 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                                  X  likes  \\\n",
       "0          0  i feel so shitty about my body today I want to...    1.0   \n",
       "1          4  i want you to make yourself your lunch and let...    3.0   \n",
       "2          6                         ..Wanna go get some lunch?    0.0   \n",
       "3          9  hello! not new to edtwt (switched accs) + look...    4.0   \n",
       "4         10  20-30 min wait to get a dosa at avrebele mela ...    0.0   \n",
       "...      ...                                                ...    ...   \n",
       "20140  25390  does the 'thinking' time counter on CELTX vs t...    2.0   \n",
       "20141  25391  Pinto Beans w/smoked Turkey Wings and cornbrea...    1.0   \n",
       "20142  25393  Back to normal life in Los Angeles means back ...   11.0   \n",
       "20143  25396  At some point a certain brand of skinny fitnes...    7.0   \n",
       "20144  25398  Ordered a portable smoothie maker for when I'm...    6.0   \n",
       "\n",
       "       followers  popularity  y  \n",
       "0          343.0    0.829554  1  \n",
       "1          277.0    1.710159  2  \n",
       "2          329.0    0.417281  0  \n",
       "3           14.0    3.127792  2  \n",
       "4           98.0    0.489201  0  \n",
       "...          ...         ... ..  \n",
       "20140      138.0    1.405926  1  \n",
       "20141     2088.0    0.575502  1  \n",
       "20142     6372.0    2.237816  2  \n",
       "20143      377.0    3.272493  2  \n",
       "20144      483.0    2.756539  2  \n",
       "\n",
       "[19741 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop duplicates observations, keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='X', keep='first')\n",
    "print(df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc25a3-4a04-41e9-80ea-0007fcee0ba7",
   "metadata": {},
   "source": [
    "Generate response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0a3e2-e475-4b15-b302-34b7c72a1806",
   "metadata": {},
   "source": [
    "### Training Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5d713d-ebe6-4f31-97b1-7a69490b0c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'X', 'likes', 'followers'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "203      What is the keto diet:\\n\\nThe ketogenic diet o...\n",
       "16767    I just love how Mexican food is just like ‚Äúbut...\n",
       "1529     ü§ç 01/05 calories\\n‚ÅÉbreakfast: +450\\n‚ÅÉlunch: +5...\n",
       "11011                                  I love yakisoba bun\n",
       "9673     I made chocolate chip cookies &amp; didn‚Äôt thi...\n",
       "                               ...                        \n",
       "15838    She fell in love with smashing a pl√°tano she s...\n",
       "8068     new comfort food i could eat everyday unlocked...\n",
       "19431    // Doing hospitality and one of the people I a...\n",
       "4472          I was late from lunch reading this damn book\n",
       "3355     I have a list of errands to run but I also wan...\n",
       "Name: X, Length: 15792, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0.470836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>0</td>\n",
       "      <td>0.473586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1</td>\n",
       "      <td>1.239854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11011</th>\n",
       "      <td>0</td>\n",
       "      <td>0.466117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9673</th>\n",
       "      <td>1</td>\n",
       "      <td>0.954954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15838</th>\n",
       "      <td>0</td>\n",
       "      <td>0.436263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19431</th>\n",
       "      <td>0</td>\n",
       "      <td>0.426268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.413044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>1</td>\n",
       "      <td>1.160578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15792 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y  popularity\n",
       "203    0    0.470836\n",
       "16767  0    0.473586\n",
       "1529   1    1.239854\n",
       "11011  0    0.466117\n",
       "9673   1    0.954954\n",
       "...   ..         ...\n",
       "15838  0    0.436263\n",
       "8068   0    0.432671\n",
       "19431  0    0.426268\n",
       "4472   0    0.413044\n",
       "3355   1    1.160578\n",
       "\n",
       "[15792 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sec_col = 'popularity'\n",
    "y_col = ['y', sec_col] ####\n",
    "####y_col = ['y'] ####\n",
    "X_cols = df.columns\n",
    "X_cols = X_cols.drop(y_col)\n",
    "\n",
    "#X_cols = X_cols.drop('likes')\n",
    "#X_cols = X_cols.drop('followers')\n",
    "#X_cols = X_cols.drop('impressions')\n",
    "#X_cols = X_cols.drop('popularity') ####\n",
    "\n",
    "print(X_cols)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.loc[:,X_cols], df.loc[:,y_col], test_size=0.2, random_state=0, shuffle=True, stratify=df.loc[:,'y'])\n",
    "\n",
    "# REVIEW THIS:\n",
    "X_train = X_train['X']\n",
    "X_test = X_test['X']\n",
    "\n",
    "# backup\n",
    "X_train_bak = X_train\n",
    "X_test_bak = X_test\n",
    "\n",
    "y_train_reg = y_train[sec_col]\n",
    "y_test_reg = y_test[sec_col]\n",
    "\n",
    "y_train_clf = y_train['y']\n",
    "y_test_clf = y_test['y']\n",
    "\n",
    "display(X_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38c0e8f-f986-4f7c-872a-1868083e1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET CLASSIFICATION\n",
    "y_train = y_train_clf\n",
    "y_test = y_test_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a2d18-4534-444d-8515-7795c6fcb74d",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "We can further improve our bag-of-words pre-processing using a normalization technique called stemming.\n",
    "The idea is to reduce each word to its stem, using the stemming algorithm (rule-based heuristic).\n",
    "For example a stemmer reduce words like \"climber\", \"climbed\" and \"climbing\" to \"climb\".\n",
    "\n",
    "The Natural Language Toolkit for Python (NLTK, http://www.nltk.org) implements the Snowball stemming algorithm.\n",
    "\n",
    "#### Bag-of-Words\n",
    "\n",
    "Is used the scikit-learn implementation of bag of word using the CountVectorizer class.\n",
    "It take an array of text as input and return a bag-of-words model.\n",
    "\n",
    "##### Less frequently words\n",
    "To lower the dimension we can clean the words that appears less frequently, is used the \"min_df\" to set the minimum number of documents that the word needs to appear in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76dd029-1e6b-4656-beeb-9912b7f42a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'pink', 'sweater', 'fit', 'her', 'perfect']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare tokenization\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# create a function to \n",
    "def tokenizer_snowballStemmer(text):\n",
    "    return [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "tokenizer_snowballStemmer(\"The pink sweater fit her perfectly\") # test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a58e08-37cd-494c-9cab-e05821acb438",
   "metadata": {},
   "source": [
    "Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ecf08e-bff3-4cca-a97e-5acdcb726519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def prep_bagofword(X_train, X_test):\n",
    "    count = CountVectorizer(tokenizer = tokenizer_snowballStemmer, min_df=5) # use tokenizer function\n",
    "    count.fit(X_train) # generate Bag-of-words\n",
    "\n",
    "    #print(\"Vocabulary size using stemming: {}\". format(len(count.vocabulary_)))\n",
    "    #print(\"Vocabulary content:\\n {}\".format(count.vocabulary_))\n",
    "\n",
    "    # apply transformation to the data\n",
    "    X_train = count.transform(X_train)\n",
    "    print(\"X_train: {}\".format(X_train.shape))\n",
    "\n",
    "    X_test = count.transform(X_test)\n",
    "    print(\"X_test: {}\".format(X_test.shape))\n",
    "    \n",
    "    feature_names = np.array(count.get_feature_names())\n",
    "    \n",
    "    return X_train, X_test, feature_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b7c68-8baf-4360-9eef-880ca093a29f",
   "metadata": {},
   "source": [
    "Better use bag of word + TF-IDF\n",
    "\n",
    "REFs \n",
    "https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f509602-77a2-4275-a6dc-5f196c58ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "\n",
    "def prep_bagofword_tfidf(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer = tokenizer_snowballStemmer,\n",
    "        max_df=0.50,\n",
    "        min_df=20,\n",
    "        #ngram_range=(1,5),\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    vectorizer.fit(X_train)\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "    print(f\"vectorization done in {time.time() - t0:.3f} s\")\n",
    "\n",
    "    print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n",
    "    print(f\"{X_train.nnz / np.prod(X_train.shape):.3f}\")\n",
    "\n",
    "    #print(\"Vocabulary size using stemming: {}\". format(len(count.vocabulary_)))\n",
    "    #print(\"Vocabulary content:\\n {}\".format(vectorizer.vocabulary_))\n",
    "\n",
    "    # apply transformation to the tesr\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    print(\"X_test: {}\".format(X_test.shape))\n",
    "\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    return X_train, X_test, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c424a93-edaa-4d5c-a29c-03ecf1d5903f",
   "metadata": {},
   "source": [
    "Main preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062b906b-62f0-4833-af26-3a0d55a635cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization done in 6.357 s\n",
      "n_samples: 15792, n_features: 1280\n",
      "0.006\n",
      "X_test: (3949, 1280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# update the variables\n",
    "#X_train = X_train_bak\n",
    "#X_test = X_test_bak\n",
    "\n",
    "# select steps to apply\n",
    "#X_train, X_test, feature_names = prep_bagofword(X_train, X_test)\n",
    "\n",
    "# update the variables\n",
    "X_train = X_train_bak\n",
    "X_test = X_test_bak\n",
    "\n",
    "X_train, X_test, feature_names = prep_bagofword_tfidf(X_train, X_test)\n",
    "\n",
    "# in case of classification\n",
    "target_names = [0, 1 ,2]\n",
    "display(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea903bb4-29e1-401b-9e47-3ed258348a55",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984af4b7-41e6-4433-8e9b-dc7570145f34",
   "metadata": {},
   "source": [
    "For Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e1c4f-daa1-4d8e-93cd-6a84a13f987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':(100, 200),\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "gs_rf = GridSearchCV(rf, parameters)\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ea08d-b52a-4a09-93cd-745fdaa7b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"These are the results:\")\n",
    "display(sorted(gs_rf.cv_results_.keys()))\n",
    "display(\"You can choose to see them:\")\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % gs_rf.best_score_)\n",
    "print('Best Hyperparameters: %s' % gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee1078-4611-43ba-8ee5-5e08d96931e0",
   "metadata": {},
   "source": [
    "For Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a86c9b8-4b7b-40ea-8af0-1d48744085e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LinearSVC(), param_grid={&#x27;C&#x27;: (1, 2)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LinearSVC(), param_grid={&#x27;C&#x27;: (1, 2)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(), param_grid={'C': (1, 2)})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'C':(1, 2),\n",
    "}\n",
    "\n",
    "svc = LinearSVC()\n",
    "gs_svc = GridSearchCV(svc, parameters)\n",
    "gs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6257c7d4-e5c6-432c-aebe-c0c4d45c7073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.43230716304391625\n",
      "Best Hyperparameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % gs_svc.best_score_)\n",
    "print('Best Hyperparameters: %s' % gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417c69a-ad70-4ab4-a443-9dc0ed137af2",
   "metadata": {},
   "source": [
    "For Gaussian SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4655670-2efe-4822-bf70-29047057642b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(kernel=&#x27;poly&#x27;), param_grid={&#x27;C&#x27;: (1, 2)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(kernel=&#x27;poly&#x27;), param_grid={&#x27;C&#x27;: (1, 2)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='poly'), param_grid={'C': (1, 2)})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'C':(1, 2),\n",
    "}\n",
    "\n",
    "svc_k = SVC(kernel='poly')\n",
    "gs_svc_k = GridSearchCV(svc_k, parameters)\n",
    "gs_svc_k.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2509312-fb58-4c51-be92-57001c39f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % gs_svc_k.best_score_)\n",
    "print('Best Hyperparameters: %s' % gs_svc_k.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92423481-d043-48f4-84a6-cd80fc2b0a3e",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb3a93-c529-4896-a8ac-1a78dae10399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def model_randomforest(X_train, y_train):\n",
    "    # fit a Random Forest model\n",
    "    clf_empty = RandomForestClassifier(n_estimators=100)\n",
    "    clf_fitted = clf_empty.fit(X_train, y_train) \n",
    "    return clf_empty, clf_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a568928-920a-42fa-a5f8-f7698ad480ff",
   "metadata": {},
   "source": [
    "Check the model performance using cross validation (on the training set) and show the accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc297a-8f72-4ee4-aaf1-e2cd81bec709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_cv_classification(clf, X_train, y_train):\n",
    "    # plot CV results\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='balanced_accuracy')\n",
    "    display(\"CROSS VALIDATION\")\n",
    "    display(\"Cross Validation scores\")\n",
    "    i=1\n",
    "    for a in scores:\n",
    "        display(\"Accuracy cv=\" + str(i) + \": \" + str(round(a*100, 2)))\n",
    "        i = i+1\n",
    "    acc_mean = round(scores.mean(),2)*100\n",
    "    display(\"Accuracy MEAN: \"+str(acc_mean))\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b42da-2198-420a-87f2-3df9029b32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def eval_pred_classification(clf, X_test, y_test):\n",
    "    display(\"TEST SET\")\n",
    "    # results on test set\n",
    "    predictions = clf.predict(X_test)\n",
    "    test_accuracy = balanced_accuracy_score(predictions, y_test)\n",
    "    display(\"Test set accuracy: \" + str(round(test_accuracy*100, 2)))\n",
    "    display(confusion_matrix(predictions, y_test)) # display confusion matrix\n",
    "\n",
    "    # results on test set\n",
    "    predictions = clf.predict(X_test)\n",
    "    test_accuracy = balanced_accuracy_score(predictions, y_test)\n",
    "    display(\"Test set accuracy: \" + str(round(test_accuracy*100, 2)))\n",
    "\n",
    "    cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=clf.classes_)\n",
    "    disp.plot()\n",
    "\n",
    "    fig = disp.ax_.get_figure()\n",
    "    fig.set_figwidth(2)\n",
    "    fig.set_figheight(2)\n",
    "\n",
    "    plt.title(\"Test set results\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aedbfd-bc7c-4e74-9930-eff1075f9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "clf_empty, clf_fitted = model_randomforest(X_train, y_train)\n",
    "\n",
    "# Cross Validation\n",
    "eval_cv_classification(clf_empty, X_train, y_train)\n",
    "\n",
    "# validation set\n",
    "eval_pred_classification(clf_fitted, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661e043-f596-4c4d-98a2-93ada2f6eaf5",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "Benchmarking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86617383-6f18-4a97-b655-af43fa211b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "def benchmark(clf, custom_name=False):\n",
    "    \n",
    "    score_cv = eval_cv_classification(clf, X_train, y_train)\n",
    "    \n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(f\"train time: {train_time:.3}s\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "    print(f\"test time:  {test_time:.3}s\")\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(f\"accuracy:   {score:.3}\")\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(f\"dimensionality: {clf.coef_.shape[1]}\")\n",
    "        print(f\"density: {density(clf.coef_)}\")\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    if custom_name:\n",
    "        clf_descr = str(custom_name)\n",
    "    else:\n",
    "        clf_descr = clf.__class__.__name__\n",
    "        \n",
    "    return clf_descr, score, train_time, test_time, score_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfd5a5-a63a-4c89-ad65-94e1c1860ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "    (LogisticRegression(C=5, max_iter=1000), \"Logistic Regression\"),\n",
    "    (KNeighborsClassifier(n_neighbors=100), \"kNN\"),\n",
    "    (RandomForestClassifier(), \"Random Forest\"),\n",
    "    # L2 penalty Linear SVC\n",
    "    (LinearSVC(C=0.1, dual=False, max_iter=1000), \"Linear SVC\"),\n",
    "    # Sparse naive Bayes classifier\n",
    "    (ComplementNB(alpha=0.1), \"Complement naive Bayes\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c53dc-d65e-4f81-9106-650541a90b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(5)]\n",
    "\n",
    "clf_names, score, training_time, test_time, score_cv = results\n",
    "training_time = np.array(training_time)\n",
    "test_time = np.array(test_time)\n",
    "\n",
    "# accuracy cv\n",
    "\n",
    "fig = plt.figure(figsize = (5, 3))\n",
    " \n",
    "# creating the bar plot\n",
    "ax = plt.bar(clf_names, score_cv, color ='green', width = 0.4)\n",
    "\n",
    "plt.xticks(ha='right', rotation=20, fontsize=8)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"CV accuracy results\")\n",
    "plt.show()\n",
    "    \n",
    "# accuracy validation\n",
    "fig, ax1 = plt.subplots(figsize=(8, 4), dpi=80)\n",
    "ax1.scatter(score, training_time)\n",
    "ax1.set(\n",
    "    title=\"Score-training time trade-off\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"test accuracy\",\n",
    "    ylabel=\"training time (s)\",\n",
    ")\n",
    "fig, ax2 = plt.subplots(figsize=(8, 4), dpi=80)\n",
    "ax2.scatter(score, test_time)\n",
    "ax2.set(\n",
    "    title=\"Score-test time trade-off\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"test accuracy\",\n",
    "    ylabel=\"test time (s)\",\n",
    ")\n",
    "\n",
    "for i, txt in enumerate(clf_names):\n",
    "    ax1.annotate(txt, (score[i], training_time[i]))\n",
    "    ax2.annotate(txt, (score[i], test_time[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116682b-4f8c-4fc8-9a3b-0dd36d2e9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# results on test set\n",
    "predictions = dummy_clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(predictions, y_test)\n",
    "display(\"Test set accuracy: \" + str(round(test_accuracy*100, 2)))\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions, labels=dummy_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=dummy_clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "fig = disp.ax_.get_figure()\n",
    "fig.set_figwidth(2)\n",
    "fig.set_figheight(2)\n",
    "\n",
    "plt.title(\"Test set results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf6827-0fa7-40fb-b7d1-045ee6e74a02",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92762f-7f9d-41b4-841a-8506c63a579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_reg\n",
    "y_test = y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63214e9d-5f43-428f-8b44-ce30b841073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# plot CV results\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='r2')\n",
    "display(\"Cross Validation scores on popularity\")\n",
    "i=1\n",
    "for a in scores:\n",
    "    display(\"R^2 cv=\" + str(i) + \": \" + str(round(a*100, 2)))\n",
    "    i = i+1\n",
    "\n",
    "display(\"R^2 MEAN: \"+str(round(scores.mean(),2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1f62c-8b99-4d39-bc6a-f4d217917154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVC\n",
    "#clf = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#display(clf.score(X_test, y_test))\n",
    "\n",
    "clf = DummyRegressor(strategy=\"mean\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "display(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1386507-2d47-42ca-b4d5-90475395d641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
